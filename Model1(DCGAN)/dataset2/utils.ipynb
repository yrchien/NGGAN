{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer\n",
    "# %load utils.py\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import librosa\n",
    "import argparse\n",
    "import pescador\n",
    "import numpy as np\n",
    "from config import *\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import csv\n",
    "from scipy import signal\n",
    "\n",
    "freq = 400000\n",
    "\n",
    "LOGGER = logging.getLogger('specgan')\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "\n",
    "def make_path(output_path):\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    return output_path\n",
    "\n",
    "traindata = DATASET_NAME\n",
    "output = make_path(OUTPUT_PATH)\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "        \n",
    "def save_and_plot(epoch_samples, epoch, output_dir):\n",
    "    \"\"\"\n",
    "    Save output samples.\n",
    "    \"\"\"\n",
    "    sample_dir = make_path(os.path.join(output_dir, str(epoch))) \n",
    "    fs = freq\n",
    "    # save_timeseries\n",
    "    data = []\n",
    "    for i in range(len(epoch_samples)):\n",
    "        data.append( spectrogram_to_time(epoch_samples[i])[1] )\n",
    "    \n",
    "    # plot spectrogram\n",
    "    cm=plt.cm.get_cmap('plasma')\n",
    "    plt.figure(figsize=(30,10))\n",
    "\n",
    "    plt.pcolormesh(epoch_samples[0],cmap=cm)\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"spectrogram_0.png\") \n",
    "    \n",
    "    plt.clf()\n",
    "    for i in range(len(epoch_samples)):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.pcolormesh(epoch_samples[i],cmap=cm)\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"spectrogram.png\") # put this command forward show\n",
    "    \n",
    "    # plot time series\n",
    "    plt.clf()\n",
    "    l = len(data[0])\n",
    "    plt.plot(np.arange(0,l/fs,1/fs),data[0])\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"timeseries_0.png\")\n",
    "    \n",
    "    plt.clf()\n",
    "    for i in range(len(data)):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.plot(np.arange(0,l/fs,1/fs),data[i])\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"timeseries.png\") # put this command forward show\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.close(\"all\")\n",
    "    return sample_dir\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#### signal processing ####\n",
    "# Based on https://github.com/librosa/librosa/issues/434\n",
    "\n",
    "def _stft_forgriffin(y):\n",
    "    f, t, Zxx = signal.stft(y, fs = freq, window='blackmanharris', nperseg = 256, noverlap = 128)\n",
    "    return Zxx\n",
    "\n",
    "\n",
    "def _griffin_lim(S):\n",
    "    m = np.mean(S,axis=0)\n",
    "    S = np.vstack((m,S))\n",
    "    n = np.mean(S,axis=1)\n",
    "    n = n.reshape(-1,1)\n",
    "    S = np.hstack((S,n))\n",
    "    \n",
    "    angles = np.exp(2j * np.pi * np.random.rand(*S.shape)) \n",
    "    S_complex = np.abs(S).astype(np.complex)\n",
    "    \n",
    "    for i in range(griffin_lim_iters):\n",
    "        if i > 0:\n",
    "            angles = np.exp(1j * np.angle(_stft_forgriffin(y[1])))\n",
    "        y = _istft(S_complex * angles)\n",
    "        \n",
    "    return y\n",
    "\n",
    "def _istft(S):\n",
    "    return signal.istft(S, fs = freq, window='blackmanharris', nperseg = 256, noverlap = 128)\n",
    "\n",
    "# spectrogram to time\n",
    "def spectrogram_to_time(spectrogram):\n",
    "    tunenum = 4.2\n",
    "    spectrogram = np.power(10,(spectrogram * tunenum - tunenum))\n",
    "    estimate = _griffin_lim(spectrogram)\n",
    "    return estimate\n",
    "\n",
    "\n",
    "# Adapted from @jtcramer https://github.com/jtcramer/wavegan/blob/master/sample.py.\n",
    "def sample_generator(data, window_length=1024, fs=freq):\n",
    "    \"\"\"\n",
    "    Audio sample generator\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sample = data \n",
    "        \n",
    "    except Exception as e:\n",
    "        LOGGER.error(\"Could not load {}: {}\".format(filepath, str(e)))\n",
    "        raise StopIteration\n",
    "\n",
    "\n",
    "    # generator\n",
    "    while True:\n",
    "        \n",
    "        tune_num = 4.2\n",
    "        fr, times, Zxx = signal.stft(data, fs=freq, window='blackmanharris', nperseg=256, noverlap=128)  \n",
    "        X_norm = ( np.log10(abs(Zxx[1:,:-1])) + tune_num ) / tune_num\n",
    "        X_norm = X_norm.astype('float32')  \n",
    "        \n",
    "        assert not np.any(np.isnan(X_norm))\n",
    "\n",
    "        yield {'X': X_norm}\n",
    "\n",
    "def batch_generator(datas, batch_size):\n",
    "    streamers = []\n",
    "    for i in range(len(datas)):\n",
    "        s = pescador.Streamer(sample_generator, datas[i])\n",
    "        streamers.append(s)\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "\n",
    "    return batch_gen\n",
    "\n",
    "\n",
    "def numpy_to_var(numpy_data, cuda):\n",
    "    \"\"\"\n",
    "    Convert numpy array to Variable.\n",
    "    \"\"\"\n",
    "    data = numpy_data[:, np.newaxis, : , :]\n",
    "    data = torch.Tensor(data)\n",
    "    if cuda:\n",
    "        data = data.cuda()\n",
    "    return Variable(data, requires_grad=False)\n",
    "        \n",
    "\n",
    "\n",
    "def plot_loss(D_loss, G_loss, save_path):\n",
    "    \n",
    "\n",
    "    save_path = os.path.join(save_path, \"loss_curve.png\")\n",
    "\n",
    "    x = range(len(D_loss))\n",
    "\n",
    "    y1 = D_loss\n",
    "    y2 = G_loss\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    Get command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Train a WaveGAN on a given set of audio')\n",
    "\n",
    "    parser.add_argument('-ms', '--model-size', dest='model_size', type=int, default=4,\n",
    "                        help='Model size parameter used in WaveGAN')\n",
    "    \n",
    "    parser.add_argument('-pssf', '--phase-shuffle-shift-factor', dest='shift_factor', type=int, default=2,\n",
    "                        help='Maximum shift used by phase shuffle')\n",
    "    \n",
    "    parser.add_argument('-psb', '--phase-shuffle-batchwise', dest='batch_shuffle', action='store_true',\n",
    "                        help='If true, apply phase shuffle to entire batches rather than individual samples')\n",
    "    \n",
    "    parser.add_argument('-ppfl', '--post-proc-filt-len', dest='post_proc_filt_len', type=int, default=512,\n",
    "                        help='Length of post processing filter used by generator. Set to 0 to disable.')\n",
    "    \n",
    "    parser.add_argument('-lra', '--lrelu-alpha', dest='alpha', type=float, default=0.2,\n",
    "                        help='Slope of negative part of LReLU used by discriminator')\n",
    "    \n",
    "    parser.add_argument('-vr', '--valid-ratio', dest='valid_ratio', type=float, default=0.1,\n",
    "                        help='Ratio of audio files used for validation')\n",
    "    \n",
    "    parser.add_argument('-tr', '--test-ratio', dest='test_ratio', type=float, default=0.1,\n",
    "                        help='Ratio of audio files used for testing')\n",
    "    \n",
    "    parser.add_argument('-bs', '--batch-size', dest='batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='Batch size used for training')\n",
    "    \n",
    "    parser.add_argument('-ne', '--num-epochs', dest='num_epochs', type=int, default=EPOCHS, help='Number of epochs')\n",
    "    \n",
    "    parser.add_argument('-ng', '--ngpus', dest='ngpus', type=int, default=4,\n",
    "                        help='Number of GPUs to use for training')\n",
    "    \n",
    "    parser.add_argument('-ld', '--latent-dim', dest='latent_dim', type=int, default=100,\n",
    "                        help='Size of latent dimension used by generator')\n",
    "    \n",
    "    parser.add_argument('-eps', '--epochs-per-sample', dest='epochs_per_sample', type=int, default=SAMPLE_EVERY,\n",
    "                        help='How many epochs between every set of samples generated for inspection')\n",
    "    \n",
    "    parser.add_argument('-ss', '--sample-size', dest='sample_size', type=int, default=SAMPLE_NUM,\n",
    "                        help='Number of inspection samples generated')\n",
    "    \n",
    "    parser.add_argument('-rf', '--regularization-factor', dest='lmbda', type=float, default=10.0,\n",
    "                        help='Gradient penalty regularization factor')\n",
    "    \n",
    "    parser.add_argument('-lr', '--learning-rate', dest='learning_rate', type=float, default=0.0002,\n",
    "                        help='Initial ADAM learning rate')\n",
    "    \n",
    "    parser.add_argument('-bo', '--beta-one', dest='beta1', type=float, default=0.5, help='beta_1 ADAM parameter')\n",
    "    \n",
    "    parser.add_argument('-bt', '--beta-two', dest='beta2', type=float, default=0.9999, help='beta_2 ADAM parameter')\n",
    "    \n",
    "    parser.add_argument('-v', '--verbose', dest='verbose', action='store_true')\n",
    "    \n",
    "    parser.add_argument('-audio_dir', '--audio_dir', dest='audio_dir', type=str, default=traindata, help='Path to directory containing audio files')\n",
    "    \n",
    "    parser.add_argument('-output_dir', '--output_dir', dest='output_dir', type=str, default=output, help='Path to directory where model files will be output')\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "   \n",
    "    return vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
