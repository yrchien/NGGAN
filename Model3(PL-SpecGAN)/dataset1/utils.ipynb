{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer\n",
    "# %load utils.py\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import pescador\n",
    "import numpy as np\n",
    "from config import *\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from scipy import signal\n",
    "\n",
    "LOGGER = logging.getLogger('specgan')\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "\n",
    "freq = 400000\n",
    "\n",
    "def make_path(output_path):\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    return output_path\n",
    "\n",
    "traindata = DATASET_NAME\n",
    "output = make_path(OUTPUT_PATH)\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "        \n",
    "def save_and_plot( t, f, epoch_samples, epoch, output_dir): # 10,2,128,128\n",
    "    \"\"\"\n",
    "    Save output samples.\n",
    "    \"\"\"\n",
    "    fs = freq\n",
    "    sample_dir = make_path(os.path.join(output_dir, str(epoch))) \n",
    "    # save_timeseries\n",
    "    data = []\n",
    "    for i in range(len(epoch_samples)):\n",
    "        data.append( spectrogram_to_time(epoch_samples[i])[1] )\n",
    "    \n",
    "    \n",
    "    cm=plt.cm.get_cmap('rainbow') \n",
    "    plt.figure(figsize=(30,10))\n",
    "\n",
    "    plt.pcolormesh(t, f, epoch_samples[0][0],cmap=cm)\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"amplitude spectrum.png\") \n",
    "    plt.clf()\n",
    "    \n",
    "    plt.pcolormesh(t, f, epoch_samples[0][1],cmap=cm)\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"phase spectrum.png\") \n",
    "    \n",
    "    # plot time series\n",
    "    plt.clf()\n",
    "    l = len(data[0])\n",
    "    plt.plot(np.arange(0,l/fs,1/fs),data[0])\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"timeseries_0.png\")\n",
    "    \n",
    "    plt.close(\"all\")\n",
    "    return sample_dir\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#### signal processing ####\n",
    "# Based on https://github.com/librosa/librosa/issues/434\n",
    "\n",
    "# def _stft_forgriffin(y):\n",
    "#     f, t, Zxx = signal.stft(y, fs=freq, nperseg=256, noverlap=128)\n",
    "#     return Zxx\n",
    "\n",
    "# def _griffin_lim(S):\n",
    "#     m = np.mean(S,axis=0)\n",
    "#     S = np.vstack((m,S))\n",
    "#     n = np.mean(S,axis=1)\n",
    "#     n = n.reshape(-1,1)\n",
    "#     S = np.hstack((S,n))\n",
    "    \n",
    "#     angles = np.exp(2j * np.pi * np.random.rand(*S.shape)) # S.shape = (128*128)\n",
    "#     S_complex = np.abs(S).astype(np.complex)\n",
    "    \n",
    "#     for i in range(griffin_lim_iters):\n",
    "#         if i > 0:\n",
    "#             angles = np.exp(1j * np.angle(_stft_forgriffin(y[1])))\n",
    "#         y = _istft(S_complex * angles)\n",
    "#     return y\n",
    "\n",
    "def _istft(S):\n",
    "    return signal.istft(S, fs=freq, nperseg=256, noverlap=128)\n",
    "\n",
    "# spectrogram to time\n",
    "def spectrogram_to_time(spectrogram): # 2,128,128\n",
    "    # abs\n",
    "    minva = -5\n",
    "    lownum = 1e-8\n",
    "    Zxx2denor = spectrogram[0]*abs(minva) + minva\n",
    "    Zxx2dbtoamp = np.power(10,Zxx2denor)- lownum\n",
    "    \n",
    "    m = np.mean(Zxx2dbtoamp,axis=0)\n",
    "    Zxx2dbtoamp = np.vstack((m,Zxx2dbtoamp))\n",
    "    n = np.mean(Zxx2dbtoamp,axis=1)\n",
    "    n = n.reshape(-1,1)\n",
    "    Zxx2dbtoamp = np.hstack((Zxx2dbtoamp,n))\n",
    "    \n",
    "    \n",
    "    # phase\n",
    "    finetuneangle = 3.15\n",
    "    phase = spectrogram[1] * finetuneangle \n",
    "    m = np.mean(phase,axis=0)\n",
    "    phase = np.vstack((m,phase))\n",
    "    n = np.mean(phase,axis=1)\n",
    "    n = n.reshape(-1,1)\n",
    "    phase = np.hstack((phase,n))\n",
    "    \n",
    "    # estimate \n",
    "    estimate = _istft( Zxx2dbtoamp * np.exp(1j*phase) )\n",
    "    \n",
    "    return estimate \n",
    "\n",
    "# time to spectrogram\n",
    "def time_to_mixabsphase(time_series):\n",
    "    f, t, Zxx = signal.stft(time_series, fs=freq, nperseg=256, noverlap=128)\n",
    "    t = t[:-1]\n",
    "    f = f[:-1]\n",
    "    Zxx = Zxx[1:,:-1]\n",
    "    \n",
    "    # handle abs \n",
    "    lownum = 1e-8\n",
    "    Zxx2 = abs(Zxx) + lownum\n",
    "    Zxx2log = np.log10(Zxx2)\n",
    "    minva = -5\n",
    "    Zxx2nor = ( Zxx2log - (minva) )/abs(minva)\n",
    "    Zxx2nor = Zxx2nor[np.newaxis,:,:]\n",
    "    \n",
    "    # handle the angle\n",
    "    phase = np.angle(Zxx)\n",
    "    finetuneangle = 3.15\n",
    "    tophase = phase / finetuneangle\n",
    "    tophase = tophase[np.newaxis,:,:]\n",
    "    \n",
    "    return np.vstack((Zxx2nor,tophase))\n",
    "\n",
    "# Adapted from @jtcramer https://github.com/jtcramer/wavegan/blob/master/sample.py.\n",
    "def sample_generator(data, window_length=16384, fs=freq):\n",
    "    \"\"\"\n",
    "    Audio sample generator\n",
    "    \"\"\"\n",
    "    # Pad audio to >= window_length.\n",
    "    audio_len = len(data)\n",
    "\n",
    "    while True:\n",
    "        # signal processing\n",
    "        X_norm = time_to_mixabsphase(data)  \n",
    "        X_norm = X_norm.astype('float32')  \n",
    "        \n",
    "        assert not np.any(np.isnan(X_norm))\n",
    "\n",
    "        yield {'X': X_norm}\n",
    "\n",
    "def batch_generator(datas, batch_size):\n",
    "    streamers = []\n",
    "    for i in range(len(datas)):\n",
    "        s = pescador.Streamer(sample_generator, datas[i])\n",
    "        streamers.append(s)\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "\n",
    "    return batch_gen\n",
    "\n",
    "\n",
    "def get_all_audio_filepaths(audio_dir):\n",
    "    return [os.path.join(root, fname)\n",
    "            for (root, dir_names, file_names) in os.walk(audio_dir, followlinks=True)\n",
    "            for fname in file_names\n",
    "            if (fname.lower().endswith('.wav') or fname.lower().endswith('.mp3'))]\n",
    "\n",
    "\n",
    "def split_data(audio_path_list, valid_ratio, test_ratio, batch_size):\n",
    "    num_files = len(audio_path_list)\n",
    "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
    "    num_test = int(np.ceil(num_files * test_ratio))\n",
    "    num_train = num_files - num_valid - num_test\n",
    "\n",
    "    if not (num_valid > 0 and num_test > 0 and num_train > 0):\n",
    "        LOGGER.error(\"Please download DATASET '{}' and put it under current path !\".format(DATASET_NAME))\n",
    "\n",
    "    # Random shuffle the audio_path_list for splitting.\n",
    "    random.shuffle(audio_path_list)\n",
    "\n",
    "    valid_files = audio_path_list[:num_valid]\n",
    "    test_files = audio_path_list[num_valid:num_valid + num_test]\n",
    "    train_files = audio_path_list[num_valid + num_test:]\n",
    "    train_size = len(train_files)\n",
    "\n",
    "\n",
    "    train_data = batch_generator(train_files, batch_size)\n",
    "    valid_data = batch_generator(valid_files, batch_size)\n",
    "    test_data = batch_generator(test_files, batch_size)\n",
    "\n",
    "    return train_data, valid_data, test_data, train_size   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def numpy_to_var(numpy_data, cuda):\n",
    "    \"\"\"\n",
    "    Convert numpy array to Variable.\n",
    "    \"\"\"\n",
    "#     data = numpy_data[:, np.newaxis, : , :]\n",
    "    data = torch.Tensor(numpy_data)\n",
    "    if cuda:\n",
    "        data = data.cuda()\n",
    "    return Variable(data, requires_grad=False)\n",
    "        \n",
    "\n",
    "    \n",
    "# Adapted from https://github.com/caogang/wgan-gp/blob/master/gan_toy.py\n",
    "def calc_gradient_penalty(net_dis, real_data, fake_data, batch_size, lmbda, use_cuda=False):\n",
    "    # Compute interpolation factors\n",
    "    alpha = torch.rand(batch_size, 2 , 1 , 1)\n",
    "    alpha = alpha.expand(real_data.size()) \n",
    "    alpha = alpha.cuda() if use_cuda else alpha\n",
    "\n",
    "    # Interpolate between real and fake data.\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data # batch * num_channel * 128*128\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    # Evaluate discriminator\n",
    "    disc_interpolates = net_dis(interpolates) \n",
    "\n",
    "    # Obtain gradients of the discriminator with respect to the inputs\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates, \n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else\n",
    "                              torch.ones(disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0] # batch 2 128 128\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), 2 , 128 , -1)\n",
    "\n",
    "    # Compute MSE between 1.0 and the gradient of the norm penalty to make discriminator\n",
    "    # to be a 1-Lipschitz function.\n",
    "    gradient_penalty = lmbda * ( ( gradients.norm(2, dim=(2,3) ) - 1) ** 2 ).mean()\n",
    "    return gradient_penalty   \n",
    "\n",
    "def plot_loss(D_cost_train, D_wass_train, D_cost_valid, D_wass_valid,\n",
    "              G_cost, save_path):\n",
    "    assert len(D_cost_train) == len(D_wass_train) == len(D_cost_valid) == len(D_wass_valid) == len(G_cost)\n",
    "\n",
    "    save_path = os.path.join(save_path, \"loss_curve.png\")\n",
    "\n",
    "    x = range(len(D_cost_train))\n",
    "\n",
    "    y1 = D_cost_train\n",
    "    y2 = D_wass_train\n",
    "    y3 = D_cost_valid\n",
    "    y4 = D_wass_valid\n",
    "    y5 = G_cost\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss_train')\n",
    "    plt.plot(x, y2, label='D_wass_train')\n",
    "    plt.plot(x, y3, label='D_loss_valid')\n",
    "    plt.plot(x, y4, label='D_wass_valid')\n",
    "    plt.plot(x, y5, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    Get command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Train a WaveGAN on a given set of audio')\n",
    "\n",
    "    parser.add_argument('-ms', '--model-size', dest='model_size', type=int, default=64,\n",
    "                        help='Model size parameter used in WaveGAN')\n",
    "    parser.add_argument('-pssf', '--phase-shuffle-shift-factor', dest='shift_factor', type=int, default=2,\n",
    "                        help='Maximum shift used by phase shuffle')\n",
    "    parser.add_argument('-psb', '--phase-shuffle-batchwise', dest='batch_shuffle', action='store_true',\n",
    "                        help='If true, apply phase shuffle to entire batches rather than individual samples')\n",
    "    parser.add_argument('-ppfl', '--post-proc-filt-len', dest='post_proc_filt_len', type=int, default=512,\n",
    "                        help='Length of post processing filter used by generator. Set to 0 to disable.')\n",
    "    parser.add_argument('-lra', '--lrelu-alpha', dest='alpha', type=float, default=0.2,\n",
    "                        help='Slope of negative part of LReLU used by discriminator')\n",
    "    parser.add_argument('-vr', '--valid-ratio', dest='valid_ratio', type=float, default=0.1,\n",
    "                        help='Ratio of audio files used for validation')\n",
    "    parser.add_argument('-tr', '--test-ratio', dest='test_ratio', type=float, default=0.1,\n",
    "                        help='Ratio of audio files used for testing')\n",
    "    parser.add_argument('-bs', '--batch-size', dest='batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='Batch size used for training')\n",
    "    parser.add_argument('-ne', '--num-epochs', dest='num_epochs', type=int, default=EPOCHS, help='Number of epochs')\n",
    "    parser.add_argument('-ng', '--ngpus', dest='ngpus', type=int, default=4,\n",
    "                        help='Number of GPUs to use for training')\n",
    "    parser.add_argument('-ld', '--latent-dim', dest='latent_dim', type=int, default=100,\n",
    "                        help='Size of latent dimension used by generator')\n",
    "    parser.add_argument('-eps', '--epochs-per-sample', dest='epochs_per_sample', type=int, default=SAMPLE_EVERY,\n",
    "                        help='How many epochs between every set of samples generated for inspection')\n",
    "    parser.add_argument('-ss', '--sample-size', dest='sample_size', type=int, default=SAMPLE_NUM,\n",
    "                        help='Number of inspection samples generated')\n",
    "    parser.add_argument('-rf', '--regularization-factor', dest='lmbda', type=float, default=10.0,\n",
    "                        help='Gradient penalty regularization factor')\n",
    "    parser.add_argument('-lr', '--learning-rate', dest='learning_rate', type=float, default=1e-4,\n",
    "                        help='Initial ADAM learning rate')\n",
    "    parser.add_argument('-bo', '--beta-one', dest='beta1', type=float, default=0.5, help='beta_1 ADAM parameter')\n",
    "    parser.add_argument('-bt', '--beta-two', dest='beta2', type=float, default=0.9, help='beta_2 ADAM parameter')\n",
    "    parser.add_argument('-v', '--verbose', dest='verbose', action='store_true')\n",
    "    parser.add_argument('-audio_dir', '--audio_dir', dest='audio_dir', type=str, default=traindata, help='Path to directory containing audio files')\n",
    "    parser.add_argument('-output_dir', '--output_dir', dest='output_dir', type=str, default=output, help='Path to directory where model files will be output')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load cyclcos data\n",
    "# import csv\n",
    "# import numpy as np\n",
    "# datas = []\n",
    "# with open('firstdata.csv', newline='') as csvfile:\n",
    "# #with open('cyclo2.csv', newline='') as csvfile:\n",
    "#     rows = csv.reader(csvfile)\n",
    "#     for row in rows:\n",
    "#         datas.append( list( map(float,row) ) )\n",
    "#     csvfile.close()\n",
    "# datas = np.array(datas)\n",
    "# print(datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = time_to_mixabsphase(datas[0])\n",
    "# print(a.shape)\n",
    "# b = np.array(spectrogram_to_time(a))\n",
    "# print(b.shape)\n",
    "# print(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # signal\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import stats\n",
    "# print( stats.describe(datas[0]) )\n",
    "# fs = 360000 #360k\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(datas[0])\n",
    "# plt.plot(b[1])\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
