{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer\n",
    "# %load wavegan.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Transpose1dLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=11, upsample=None, output_padding=1):\n",
    "        super(Transpose1dLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "\n",
    "        self.upsample_layer = torch.nn.Upsample(scale_factor=upsample)\n",
    "        reflection_pad = kernel_size // 2\n",
    "        self.reflection_pad = nn.ConstantPad1d(reflection_pad, value=0)\n",
    "        self.conv1d = torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.Conv1dTrans = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            return self.conv1d(self.reflection_pad(self.upsample_layer(x)))\n",
    "        else:\n",
    "            return self.Conv1dTrans(x)\n",
    "\n",
    "\n",
    "class WaveGANGenerator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1,\n",
    "                 latent_dim=100, post_proc_filt_len=512,\n",
    "                 verbose=False, upsample=True):\n",
    "        super(WaveGANGenerator, self).__init__()\n",
    "        self.ngpus = ngpus\n",
    "        self.model_size = model_size  # d\n",
    "        self.num_channels = num_channels  # c\n",
    "        self.latent_di = latent_dim\n",
    "        self.post_proc_filt_len = post_proc_filt_len\n",
    "        self.verbose = verbose\n",
    "        # \"Dense\" is the same meaning as fully connection.\n",
    "        self.fc1 = nn.Linear(latent_dim, 256 * model_size)\n",
    "    \n",
    "        stride = 4\n",
    "        if upsample:\n",
    "            stride = 1\n",
    "            upsample = 4\n",
    "\n",
    "        self.deconv_1 = Transpose1dLayer(16 * model_size, 8 * model_size, 25, stride, upsample=upsample)\n",
    "        self.deconv_2 = Transpose1dLayer(8 * model_size, 4 * model_size, 25, stride, upsample=upsample)\n",
    "        self.deconv_3 = Transpose1dLayer(4 * model_size, 2 * model_size, 25, stride, upsample=upsample)\n",
    "        self.deconv_4 = Transpose1dLayer(2 * model_size, model_size, 25, stride, upsample=upsample)\n",
    "        self.deconv_5 = Transpose1dLayer(model_size, num_channels, 25, stride, upsample=upsample)\n",
    "\n",
    "        if post_proc_filt_len:\n",
    "            self.ppfilter1 = nn.Conv1d(num_channels, num_channels, post_proc_filt_len)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x).view(-1, 16 * self.model_size, 16)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,1024,16]\n",
    "\n",
    "        x = F.relu(self.deconv_1(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,512,64]\n",
    "\n",
    "        x = F.relu(self.deconv_2(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,256,256]\n",
    "\n",
    "        x = F.relu(self.deconv_3(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,128,1024]\n",
    "\n",
    "        x = F.relu(self.deconv_4(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,64,4096]\n",
    "\n",
    "        output = F.tanh(self.deconv_5(x))\n",
    "        #print(output.shape) [batch,1,16384]\n",
    "        return output\n",
    "\n",
    "\n",
    "class PhaseShuffle(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs phase shuffling, i.e. shifting feature axis of a 3D tensor\n",
    "    by a random integer in {-n, n} and performing reflection padding where\n",
    "    necessary.\n",
    "    \"\"\"\n",
    "    # Copied from https://github.com/jtcramer/wavegan/blob/master/wavegan.py#L8\n",
    "    def __init__(self, shift_factor):\n",
    "        super(PhaseShuffle, self).__init__()\n",
    "        self.shift_factor = shift_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.shift_factor == 0:\n",
    "            return x\n",
    "        # uniform in (L, R)\n",
    "        k_list = torch.Tensor(x.shape[0]).random_(0, 2 * self.shift_factor + 1) - self.shift_factor\n",
    "        k_list = k_list.numpy().astype(int)\n",
    "\n",
    "        # Combine sample indices into lists so that less shuffle operations\n",
    "        # need to be performed\n",
    "        k_map = {}\n",
    "        for idx, k in enumerate(k_list):\n",
    "            k = int(k)\n",
    "            if k not in k_map:\n",
    "                k_map[k] = []\n",
    "            k_map[k].append(idx)\n",
    "\n",
    "        # Make a copy of x for our output\n",
    "        x_shuffle = x.clone()\n",
    "\n",
    "        # Apply shuffle to each sample\n",
    "        for k, idxs in k_map.items():\n",
    "            if k > 0:\n",
    "                x_shuffle[idxs] = F.pad(x[idxs][..., :-k], (k, 0), mode='reflect')\n",
    "            else:\n",
    "                x_shuffle[idxs] = F.pad(x[idxs][..., -k:], (0, -k), mode='reflect')\n",
    "\n",
    "        assert x_shuffle.shape == x.shape, \"{}, {}\".format(x_shuffle.shape,\n",
    "                                                       x.shape)\n",
    "        return x_shuffle\n",
    "\n",
    "\n",
    "class PhaseRemove(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PhaseRemove, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "\n",
    "class WaveGANDiscriminator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, shift_factor=2,\n",
    "                 alpha=0.2, verbose=False):\n",
    "        super(WaveGANDiscriminator, self).__init__()\n",
    "        self.model_size = model_size  # d\n",
    "        self.ngpus = ngpus\n",
    "        self.num_channels = num_channels  # c\n",
    "        self.shift_factor = shift_factor  # n\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11)\n",
    "        self.conv2 = nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11)\n",
    "        self.conv3 = nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11)\n",
    "        self.conv4 = nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11)\n",
    "        self.conv5 = nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11)\n",
    "\n",
    "        self.ps1 = PhaseShuffle(shift_factor)\n",
    "        self.ps2 = PhaseShuffle(shift_factor)\n",
    "        self.ps3 = PhaseShuffle(shift_factor)\n",
    "        self.ps4 = PhaseShuffle(shift_factor)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * model_size, 1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #[batch,1,16384]\n",
    "\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,64,4096]\n",
    "        x = self.ps1(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,128,1024]\n",
    "        x = self.ps2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,256,256]\n",
    "        x = self.ps3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,512,64]\n",
    "        x = self.ps4(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,1024,16]\n",
    "\n",
    "        x = x.view(-1, 256 * self.model_size)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(x.shape)#[batch,16384]\n",
    "            \n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from torch.autograd import Variable\n",
    "x = Variable(torch.randn(10, 100))\n",
    "G = WaveGANGenerator(verbose=True, upsample=False)\n",
    "out = G(x)\n",
    "print(out.shape)\n",
    "D = WaveGANDiscriminator(verbose=True)\n",
    "out2 = D(out)\n",
    "print(out2.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample_layer = torch.nn.Upsample(scale_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.rand((1,1,8))\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(upsample_layer(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
