{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "developmental-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer\n",
    "# %load utils.py\n",
    "from torch import autograd\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "#import librosa\n",
    "import argparse\n",
    "import pescador\n",
    "import numpy as np\n",
    "from config import *\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#import soundfile as sf\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger('wavegan')\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def make_path(output_path):\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "traindata = DATASET_NAME\n",
    "output = make_path(OUTPUT_PATH)\n",
    "\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "# def save_samples(epoch_samples, epoch, output_dir, fs=16000):\n",
    "#     \"\"\"\n",
    "#     Save output samples.\n",
    "#     \"\"\"\n",
    "#     sample_dir = make_path(os.path.join(output_dir, str(epoch)))\n",
    "\n",
    "#     for idx, sample in enumerate(epoch_samples):\n",
    "#         output_path = os.path.join(sample_dir, \"{}.wav\".format(idx+1))\n",
    "#         sample = sample[0]\n",
    "#         #librosa.output.write_wav(output_path, sample, fs)\n",
    "#         sf.write(output_path, sample, fs)\n",
    "\n",
    "\n",
    "# Adapted from @jtcramer https://github.com/jtcramer/wavegan/blob/master/sample.py.\n",
    "# def sample_generator(filepath, window_length=16384, fs=16000):\n",
    "#     \"\"\"\n",
    "#     Audio sample generator\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         audio_data, _ = librosa.load(filepath, sr=fs) #16000\n",
    "\n",
    "#         # Clip magnitude\n",
    "#         max_mag = np.max(np.abs(audio_data))\n",
    "#         if max_mag > 1:\n",
    "#             audio_data /= max_mag\n",
    "#     except Exception as e:\n",
    "#         LOGGER.error(\"Could not load {}: {}\".format(filepath, str(e)))\n",
    "#         raise StopIteration\n",
    "\n",
    "#     # Pad audio to >= window_length.\n",
    "#     audio_len = len(audio_data)\n",
    "#     if audio_len < window_length:\n",
    "#         pad_length = window_length - audio_len\n",
    "#         left_pad = pad_length // 2\n",
    "#         right_pad = pad_length - left_pad\n",
    "\n",
    "#         audio_data = np.pad(audio_data, (left_pad, right_pad), mode='constant')\n",
    "#         audio_len = len(audio_data)\n",
    "\n",
    "#     while True:\n",
    "#         if audio_len == window_length:\n",
    "#             # If we only have a single 1*window_length audio, just yield.\n",
    "#             sample = audio_data\n",
    "#         else:\n",
    "#             # Sample a random window from the audio\n",
    "#             start_idx = np.random.randint(0, (audio_len - window_length) // 2)\n",
    "#             end_idx = start_idx + window_length\n",
    "#             sample = audio_data[start_idx:end_idx]\n",
    "\n",
    "#         sample = sample.astype('float32')  # 維度為16384的data。\n",
    "#         assert not np.any(np.isnan(sample))\n",
    "\n",
    "#         yield {'X': sample}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_all_audio_filepaths(audio_dir):\n",
    "    return [os.path.join(root, fname)\n",
    "            for (root, dir_names, file_names) in os.walk(audio_dir, followlinks=True)\n",
    "            for fname in file_names\n",
    "            if (fname.lower().endswith('.wav') or fname.lower().endswith('.mp3'))]\n",
    "\n",
    "\n",
    "def batch_generator(audio_path_list, batch_size):\n",
    "    streamers = []\n",
    "    for audio_path in audio_path_list:\n",
    "        s = pescador.Streamer(sample_generator, audio_path)\n",
    "        streamers.append(s)\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "\n",
    "    return batch_gen\n",
    "\n",
    "\n",
    "\n",
    "def split_data(audio_path_list, valid_ratio, test_ratio, batch_size):\n",
    "    num_files = len(audio_path_list)\n",
    "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
    "    num_test = int(np.ceil(num_files * test_ratio))\n",
    "    num_train = num_files - num_valid - num_test\n",
    "\n",
    "    if not (num_valid > 0 and num_test > 0 and num_train > 0):\n",
    "        LOGGER.error(\"Please download DATASET '{}' and put it under current path !\".format(DATASET_NAME))\n",
    "\n",
    "    # Random shuffle the audio_path_list for splitting.\n",
    "    random.shuffle(audio_path_list)\n",
    "\n",
    "    valid_files = audio_path_list[:num_valid]\n",
    "    test_files = audio_path_list[num_valid:num_valid + num_test]\n",
    "    train_files = audio_path_list[num_valid + num_test:]\n",
    "    train_size = len(train_files)\n",
    "\n",
    "\n",
    "    train_data = batch_generator(train_files, batch_size)\n",
    "    valid_data = batch_generator(valid_files, batch_size)\n",
    "    test_data = batch_generator(test_files, batch_size)\n",
    "\n",
    "    return train_data, valid_data, test_data, train_size\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------我修改的程式部分-------------------------------------------#\n",
    "def save_and_plot(epoch_samples, epoch, output_dir):\n",
    "    \"\"\"\n",
    "    Save output samples.\n",
    "    \"\"\"\n",
    "    sample_dir = make_path(os.path.join(output_dir, str(epoch))) \n",
    "    fs = 400000\n",
    "    # save_timeseries\n",
    "    l = len(epoch_samples[0])\n",
    "            \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(np.arange(0,l/fs,1/fs),epoch_samples[0])\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"timeseries_0.png\")\n",
    "    \n",
    "    plt.clf()\n",
    "    for i in range(len(epoch_samples)):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.plot(np.arange(0,l/fs,1/fs),epoch_samples[i])\n",
    "    plt.savefig(sample_dir + '/' + str(epoch) + \"timeseries.png\") # put this command forward show\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.close(\"all\")\n",
    "        \n",
    "\n",
    "def sample_generator1(data):\n",
    "    sample = data\n",
    "    sample = sample.astype('float32')\n",
    "    assert not np.any(np.isnan(sample))\n",
    "\n",
    "    yield {'X': sample}\n",
    "\n",
    "def batch_generator1(datas, batch_size):\n",
    "    streamers = []\n",
    "    for i in range( len(datas) ):\n",
    "        s = pescador.Streamer(sample_generator1, datas[i])\n",
    "        streamers.append(s)\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "\n",
    "    return batch_gen\n",
    "\n",
    "def split_data1(datas, valid_ratio, test_ratio, batch_size):\n",
    "    num_files = len(datas)\n",
    "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
    "    num_test = int(np.ceil(num_files * test_ratio))\n",
    "    num_train = num_files - num_valid - num_test\n",
    "\n",
    "    random.shuffle(datas)\n",
    "    valid_files = datas[:num_valid]\n",
    "    test_files = datas[num_valid:num_valid + num_test]\n",
    "    train_files = datas[num_valid + num_test:]\n",
    "    train_size = len(train_files)\n",
    "\n",
    "    train_data = batch_generator1(train_files, batch_size)\n",
    "    valid_data = batch_generator1(valid_files, batch_size)\n",
    "    test_data = batch_generator1(test_files, batch_size)\n",
    "\n",
    "    return train_data, valid_data, test_data, train_size\n",
    "\n",
    "def calc_gradient_penalty_EEG( w_gra,net_dis, real_data, fake_data, batch_size, lmbda, use_cuda=False):\n",
    "    # Compute interpolation factors\n",
    "    alpha = torch.rand(batch_size, 1, 1)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    alpha = alpha.cuda() if use_cuda else alpha\n",
    "\n",
    "    # Interpolate between real and fake data.\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data # batch * 1 * 16384\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    # Evaluate discriminator\n",
    "    disc_interpolates = net_dis(interpolates) \n",
    "\n",
    "    # Obtain gradients of the discriminator with respect to the inputs\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else\n",
    "                              torch.ones(disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1) \n",
    "    \n",
    "    gradient_penalty = max(0 , w_gra) * lmbda * ( max(0,(gradients.norm(2,dim=1) - 1)) ** 2 ) .mean()\n",
    "    \n",
    "    return gradient_penalty\n",
    "\n",
    "#----------------------------------------------我修改程式結束部分----------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/caogang/wgan-gp/blob/master/gan_toy.py\n",
    "def calc_gradient_penalty(net_dis, real_data, fake_data, batch_size, lmbda, use_cuda=False):\n",
    "    # Compute interpolation factors\n",
    "    alpha = torch.rand(batch_size, 1, 1)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    alpha = alpha.cuda() if use_cuda else alpha\n",
    "\n",
    "    # Interpolate between real and fake data.\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data # batch * 1 * 16384\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    # Evaluate discriminator\n",
    "    disc_interpolates = net_dis(interpolates) \n",
    "\n",
    "    # Obtain gradients of the discriminator with respect to the inputs\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else\n",
    "                              torch.ones(disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "    # Compute MSE between 1.0 and the gradient of the norm penalty to make discriminator\n",
    "    # to be a 1-Lipschitz function.\n",
    "    gradient_penalty = lmbda * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def numpy_to_var(numpy_data, cuda):\n",
    "    \"\"\"\n",
    "    Convert numpy array to Variable.\n",
    "    \"\"\"\n",
    "    data = numpy_data[:, np.newaxis, :]\n",
    "    data = torch.Tensor(data)\n",
    "    if cuda:\n",
    "        data = data.cuda()\n",
    "    return Variable(data, requires_grad=False)\n",
    "\n",
    "\n",
    "def plot_loss(D_cost_train, D_wass_train, D_cost_valid, D_wass_valid,\n",
    "              G_cost, save_path):\n",
    "    assert len(D_cost_train) == len(D_wass_train) == len(D_cost_valid) == len(D_wass_valid) == len(G_cost)\n",
    "\n",
    "    save_path = os.path.join(save_path, \"loss_curve.png\")\n",
    "\n",
    "    x = range(len(D_cost_train))\n",
    "\n",
    "    y1 = D_cost_train\n",
    "    y2 = D_wass_train\n",
    "    y3 = D_cost_valid\n",
    "    y4 = D_wass_valid\n",
    "    y5 = G_cost\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss_train')\n",
    "    plt.plot(x, y2, label='D_wass_train')\n",
    "    plt.plot(x, y3, label='D_loss_valid')\n",
    "    plt.plot(x, y4, label='D_wass_valid')\n",
    "    plt.plot(x, y5, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    Get command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Train a WaveGAN on a given set of audio')\n",
    "\n",
    "    parser.add_argument('-ms', '--model-size', dest='model_size', type=int, default=64,\n",
    "                        help='Model size parameter used in WaveGAN')\n",
    "    parser.add_argument('-pssf', '--phase-shuffle-shift-factor', dest='shift_factor', type=int, default=2,\n",
    "                        help='Maximum shift used by phase shuffle')\n",
    "    parser.add_argument('-psb', '--phase-shuffle-batchwise', dest='batch_shuffle', action='store_true',\n",
    "                        help='If true, apply phase shuffle to entire batches rather than individual samples')\n",
    "    parser.add_argument('-ppfl', '--post-proc-filt-len', dest='post_proc_filt_len', type=int, default=512,\n",
    "                        help='Length of post processing filter used by generator. Set to 0 to disable.')\n",
    "    parser.add_argument('-lra', '--lrelu-alpha', dest='alpha', type=float, default=0.2,\n",
    "                        help='Slope of negative part of LReLU used by discriminator')\n",
    "    parser.add_argument('-vr', '--valid-ratio', dest='valid_ratio', type=float, default=0.1,\n",
    "                        help='Ratio of audio files used for validation')\n",
    "    parser.add_argument('-tr', '--test-ratio', dest='test_ratio', type=float, default=0.1,\n",
    "                        help='Ratio of audio files used for testing')\n",
    "    parser.add_argument('-bs', '--batch-size', dest='batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='Batch size used for training')\n",
    "    parser.add_argument('-ne', '--num-epochs', dest='num_epochs', type=int, default=EPOCHS, help='Number of epochs')\n",
    "    parser.add_argument('-ng', '--ngpus', dest='ngpus', type=int, default=4,\n",
    "                        help='Number of GPUs to use for training')\n",
    "    parser.add_argument('-ld', '--latent-dim', dest='latent_dim', type=int, default=100,\n",
    "                        help='Size of latent dimension used by generator')\n",
    "    parser.add_argument('-eps', '--epochs-per-sample', dest='epochs_per_sample', type=int, default=SAMPLE_EVERY,\n",
    "                        help='How many epochs between every set of samples generated for inspection')\n",
    "    parser.add_argument('-ss', '--sample-size', dest='sample_size', type=int, default=SAMPLE_NUM,\n",
    "                        help='Number of inspection samples generated')\n",
    "    parser.add_argument('-rf', '--regularization-factor', dest='lmbda', type=float, default=10.0,\n",
    "                        help='Gradient penalty regularization factor')\n",
    "    parser.add_argument('-lr', '--learning-rate', dest='learning_rate', type=float, default=1e-4,\n",
    "                        help='Initial ADAM learning rate')\n",
    "    parser.add_argument('-bo', '--beta-one', dest='beta1', type=float, default=0.5, help='beta_1 ADAM parameter')\n",
    "    parser.add_argument('-bt', '--beta-two', dest='beta2', type=float, default=0.9, help='beta_2 ADAM parameter')\n",
    "    parser.add_argument('-v', '--verbose', dest='verbose', action='store_true')\n",
    "    parser.add_argument('-audio_dir', '--audio_dir', dest='audio_dir', type=str, default=traindata, help='Path to directory containing audio files')\n",
    "    parser.add_argument('-output_dir', '--output_dir', dest='output_dir', type=str, default=output, help='Path to directory where model files will be output')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-clarity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
